{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def extract_columns_and_sort(input_file, output_file, sort_column):\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    print(\"Available columns in the dataset:\")\n",
    "    print(df.columns)\n",
    "\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    ##### checking status as operating & and technology type also solar\n",
    "    missing_columns = [col for col in ['Country/Area', 'Status', 'Technology Type'] if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Warning: The following columns are missing from the DataFrame: {missing_columns}\")\n",
    "    \n",
    "  \n",
    "    df_filtered = df[(df['Country/Area'] == 'India') & \n",
    "                     (df['Status'] == 'operating') & \n",
    "                     (df['Technology Type'] != 'Onshore')].copy()  \n",
    " \n",
    "    #### creating new columns for the next process          \n",
    "    df_filtered['ppa_capacity'] = None\n",
    "    df_filtered['unit_price'] = None\n",
    "    df_filtered['degradation_factor'] = None\n",
    "    df_filtered['aux_power'] = None\n",
    "\n",
    "    ###  checking null values by using np method and apply method\n",
    "    df_filtered['start_year_is_empty'] = np.where(df_filtered['Start year'].isnull(), 'Yes', 'No')\n",
    "    df_filtered['owner_is_empty'] = np.where(df_filtered['Owner'].isnull(), 'Yes', 'No')\n",
    "    df_filtered['ppa_tenure_is_empty'] = np.where(df_filtered['PPA Tenure'].isnull(), 'Yes', 'No')\n",
    "    df_filtered['ppa_offtaker_is_empty'] = np.where(df_filtered['PPA Offtaker'].isnull(), 'Yes', 'No')\n",
    "\n",
    "    # df_filtered['start_year_is_empty'] = df_filtered['Start year'].apply(lambda x: 'Yes' if pd.isnull(x) else 'No')\n",
    "    # df_filtered['owner_is_empty'] = df_filtered['Owner'].apply(lambda x: 'Yes' if pd.isnull(x) else 'No')\n",
    "    # df_filtered['ppa_tenure_is_empty'] = df_filtered['PPA Tenure'].apply(lambda x: 'Yes' if pd.isnull(x) else 'No')\n",
    "    # df_filtered['ppa_offtaker_is_empty'] = df_filtered['PPA Offtaker'].apply(lambda x: 'Yes' if pd.isnull(x) else 'No')\n",
    "\n",
    "\n",
    "    ### modifying phase name from -- to 1 \n",
    "    if 'Phase Name' in df.columns:\n",
    "        df_filtered['phase_name'] = df['Phase Name'].replace('--', 1)  \n",
    "    else:\n",
    "        print(\"Warning: 'Phase Name' column not found in the dataset.\")\n",
    "        df_filtered['phase_name'] = None\n",
    "\n",
    "    \n",
    "    cols = list(df_filtered.columns)\n",
    "    \n",
    "\n",
    "    ### getting location by using get_loc method \n",
    "    start_year_index = df_filtered.columns.get_loc('Start year')\n",
    "    owner_index = df_filtered.columns.get_loc('Owner')\n",
    "    ppa_tenure_index = df_filtered.columns.get_loc('PPA Tenure')\n",
    "    ppa_offtaker_index = df_filtered.columns.get_loc('PPA Offtaker')\n",
    "\n",
    "    ### removing & inserting the new column by using specific location\n",
    "    cols.remove('start_year_is_empty')\n",
    "    cols.insert(start_year_index + 1, 'start_year_is_empty')\n",
    "\n",
    "    cols.remove('owner_is_empty')\n",
    "    cols.insert(owner_index + 1, 'owner_is_empty')\n",
    "\n",
    "\n",
    "    cols.remove('ppa_tenure_is_empty')\n",
    "    cols.insert(ppa_tenure_index + 1, 'ppa_tenure_is_empty')\n",
    "\n",
    "    cols.remove('ppa_offtaker_is_empty')\n",
    "    cols.insert(ppa_offtaker_index + 1, 'ppa_offtaker_is_empty')\n",
    "\n",
    "    cols.append('phase_name')\n",
    "\n",
    "   \n",
    "    df_filtered = df_filtered[cols]\n",
    " \n",
    "    #### removing unwanted column from the uncleaned data to new data\n",
    "    unwanted_columns = [\n",
    "        'Unnamed: 0', 'Date Last Researched', 'Project Name in Local Language / Script',\n",
    "        'Retired year', 'Operator', 'Operator Name in Local Language / Script', \n",
    "        'Owner Name in Local Language / Script', 'Hydrogen', 'Other IDs (location)', \n",
    "        'Other IDs (unit/phase)'\n",
    "    ]\n",
    "\n",
    "    df_filtered = df_filtered.drop(columns=[col for col in unwanted_columns if col in df_filtered.columns])\n",
    "\n",
    "    #### checking columns null value count\n",
    "    null_counts = df_filtered.isnull().sum()\n",
    "    \n",
    "    columns_with_nulls = null_counts[null_counts > 0]\n",
    "\n",
    "    if not columns_with_nulls.empty:\n",
    "        print(\"Columns with null values:\")\n",
    "        print(columns_with_nulls)\n",
    "    else:\n",
    "        print(\"No columns with null values found.\")\n",
    "\n",
    "    ### replacing column name by using _ instead of '' (space)\n",
    "    df_filtered.columns = df_filtered.columns.str.replace(' ', '_').str.lower()\n",
    "\n",
    "    ## sorting the column by using snake case\n",
    "    sort_column_snake_case = sort_column.lower().replace(' ', '_')\n",
    "    \n",
    "    df_sorted = df_filtered.sort_values(by=sort_column_snake_case)\n",
    "\n",
    "    df_sorted.to_excel(output_file, index=False)\n",
    "    \n",
    "    ### checking unique owners\n",
    "    unique_owners = df_filtered['owner'].nunique()\n",
    "    print(f\"There are {unique_owners} unique owners in the dataset from India.\")\n",
    "    print(f\"Columns extracted, sorted by '{sort_column}', new columns added for conditions. Saved to {output_file}\")\n",
    "\n",
    "\n",
    "input_file = '/Users/sneha/Downloads/RE_technical_merged_2.xlsx'  \n",
    "output_file = 'solar_RE_data_all_column.xlsx'\n",
    "\n",
    "\n",
    "sort_column = 'Owner'\n",
    "\n",
    "\n",
    "extract_columns_and_sort(input_file, output_file, sort_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_5069/1205246945.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['plf_dq_1'].replace(['Not Available', 'not Available', 'not available',\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped, specific values in 'plf_dq_1' replaced with NaN, specific phrases removed, 'ppa_tariff_final' created, 'plf_final' with valid values created, and file saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_file = '/Users/sneha/notebook/nov14/solar_RE_data_all_column.xlsx'  \n",
    "df = pd.read_excel(input_file)\n",
    "\n",
    "### removing unwanted column \n",
    "columns_to_drop = ['phase_name1', 'phase_name2']\n",
    "df.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "## removing ppa_tariff 0 with null \n",
    "df.loc[df['ppa_tariff'] == 0, 'ppa_tariff'] = pd.NA\n",
    " \n",
    "## cleaning the NA data from the plf_dq_1 column\n",
    "if 'plf_dq_1' in df.columns:\n",
    "    df['plf_dq_1'].replace(['Not Available', 'not Available', 'not available', \n",
    "                             'Not Found', 'Unknown', 'Not available', 'Not available '], \n",
    "                            pd.NA, inplace=True)\n",
    "\n",
    "    ## removing % from the plf_dq_1 column\n",
    "    df['plf_dq_1'] = df['plf_dq_1'].apply(lambda x: str(x).replace('%', '') if isinstance(x, str) else x)\n",
    "\n",
    "    \n",
    "    df['plf_dq_1'] = df['plf_dq_1'].apply(lambda x: pd.NA if isinstance(x, str) and (\n",
    "        'More than P90 PLF estimation' in x or \n",
    "        'above degraded P90 levels' in x or \n",
    "        'P90' in x or  \n",
    "        'Plant Load Factor: 0.5' in x) else x)\n",
    "\n",
    "## cleaning capacity_rating column with null values\n",
    "df['capacity_rating'] = df['capacity_rating'].replace(['unknown', 'Unknown'], pd.NA)\n",
    "\n",
    "## removing ppa_tariff_dq_1 0 with null \n",
    "df.loc[df['ppa_tariff_dq_1'] == 0, 'ppa_tariff_dq_1'] = pd.NA\n",
    "\n",
    "### spliting the ppa_tariff & ppa_tariff_dq_1 column like value,currency,unit\n",
    "def extract_numeric_or_range(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    \n",
    "    range_match = re.search(r'(\\d+(\\.\\d+)?)\\s*-\\s*(\\d+(\\.\\d+)?)', str(value))\n",
    "    if range_match:\n",
    "        lower_value = float(range_match.group(1))\n",
    "        upper_value = float(range_match.group(3))\n",
    "        return (lower_value, upper_value)\n",
    "    \n",
    "    single_match = re.search(r'\\b\\d+(\\.\\d+)?\\b', str(value))\n",
    "    return float(single_match.group()) if single_match else pd.NA\n",
    "\n",
    "\n",
    "def extract_inr_value(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    value_str = str(value)\n",
    "  \n",
    "    if 'INR' in value_str and 'USD' in value_str:\n",
    "        match = re.search(r'INR\\s*([\\d.]+)', value_str)\n",
    "        return float(match.group(1)) if match else pd.NA\n",
    "    inr_no_space_match = re.search(r'INR([\\d.]+)', value_str)\n",
    "    if inr_no_space_match:\n",
    "        return float(inr_no_space_match.group(1))\n",
    "    return extract_numeric_or_range(value)\n",
    "\n",
    "\n",
    "def detect_currency(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    value_str = str(value).upper()\n",
    "    if any(currency in value_str for currency in ['INR', 'RS.', '₹', 'RS']):\n",
    "        return 'INR'\n",
    "    elif 'USD' in value_str or 'US$' in value_str:\n",
    "        return 'USD'\n",
    "    else:\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "def detect_unit(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NA\n",
    "    value_str = str(value).lower()\n",
    "    if any(unit in value_str for unit in ['/kwh', 'kwh', 'per kwh']):\n",
    "        return 'kWh'\n",
    "    elif any(unit in value_str for unit in ['per unit', '@ unit', \"/ unit\", \"/unit\"]):\n",
    "        return 'unit'\n",
    "    return pd.NA\n",
    "\n",
    "### applying that value to column\n",
    "df['ppa_tariff_dq1_value'] = df['ppa_tariff_dq_1'].apply(extract_inr_value)\n",
    "df['ppa_tariff_dq1_currency'] = df['ppa_tariff_dq_1'].apply(detect_currency)\n",
    "df['ppa_tariff_dq1_unit'] = df['ppa_tariff_dq_1'].apply(detect_unit)\n",
    "df['ppa_tariff_value'] = df['ppa_tariff'].apply(extract_inr_value)\n",
    "df['ppa_tariff_currency'] = df['ppa_tariff'].apply(detect_currency)\n",
    "df['ppa_tariff_unit'] = df['ppa_tariff'].apply(detect_unit)\n",
    "\n",
    "\n",
    "# df['ppa_tariff_final'] = df['ppa_tariff_dq1_value'].fillna(df['ppa_tariff_value'])\n",
    "\n",
    "### validating plf columns ,checking the range its 18 to 25 if the value is morethan or less than this value just give null\n",
    "def validate_plf(value):\n",
    "    try:\n",
    "      \n",
    "        value_float = float(value)\n",
    "        \n",
    "        \n",
    "        if 18 <= value_float <= 25:\n",
    "            return value_float\n",
    "        else:\n",
    "            return ''  \n",
    "    except (ValueError, TypeError):\n",
    "        \n",
    "        return ''\n",
    "\n",
    "### creating final plf by using above condition\n",
    "df['plf_final'] = df['plf_dq_1'].apply(validate_plf)\n",
    "\n",
    "### checking the plf value also if plf_dq_1 crt range it takes that value elif it will check plf value if its correct it will take that or\n",
    "## it will give space ''\n",
    "def validate_plf_fallback(value, fallback_value):\n",
    "    \n",
    "    if value == '':\n",
    "        \n",
    "        return validate_plf(fallback_value)\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "df['plf_final'] = df.apply(lambda row: validate_plf_fallback(row['plf_final'], row['plf']), axis=1)\n",
    "\n",
    "\n",
    "df = df.drop(columns=['value'], errors='ignore')\n",
    "\n",
    "output_file = 'solar.xlsx' \n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Columns dropped, specific values in 'plf_dq_1' replaced with NaN, specific phrases removed, 'ppa_tariff_final' created, 'plf_final' with valid values created, and file saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['phase_name'] = df_unique['phase_name'].replace({'Unit 1': '1', 'Unit 2': '2', 'Unit 3': '3'})\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_dq1_currency_unit'] = df_unique.apply(create_currency_unit_dq1, axis=1)\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_currency_unit']=df_unique.apply(create_currency_unit,axis=1)\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_dq1_value'] = pd.to_numeric(df_unique['ppa_tariff_dq1_value'], errors='coerce')\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_dq1_value_outof_range'] = df_unique.apply(\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_value_outof_range'] = df_unique.apply(\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['plf_dq1_out_of_range'] = df_unique['plf_dq_1'].apply(check_plf_out_of_range)\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['plf_final_out_of_range'] = df_unique['plf_final'].apply(check_plf_out_of_range)\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:124: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_final'] = df_unique.apply(create_ppa_tariff_final, axis=1)\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_final_empty'] = df_unique['ppa_tariff_final'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:130: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_dq_1_empty'] = df_unique['ppa_tariff_dq_1'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:131: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['plf_dq_1_empty'] = df_unique['plf_dq_1'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['ppa_tariff_final_empty'] = df_unique['ppa_tariff_final'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
      "/var/folders/1s/f_42bgbj0x30lz24x3f4f2zw0000gn/T/ipykernel_1621/2634232598.py:133: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_unique['plf_final_empty'] = df_unique['plf_final'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ppa_tariff_final column created, and file saved as solar3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "file_path = '/Users/sneha/notebook/nov19-upload_db/solar.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "### sorting the column by using owner & ppa_tariff_dq_1_value\n",
    "df_sorted = df.sort_values(by=['owner', 'ppa_tariff_dq1_value'], ascending=[True, False])\n",
    "\n",
    "## grouped the data by using project_name,phase_name and ppa_offtaker \n",
    "df_unique = df_sorted.drop_duplicates(subset=['project_name', 'phase_name', 'ppa_offtaker'], keep='first')\n",
    "\n",
    "## changing the phase name value with 1,2,3 \n",
    "df_unique['phase_name'] = df_unique['phase_name'].replace({'Unit 1': '1', 'Unit 2': '2', 'Unit 3': '3'})\n",
    "\n",
    "### creating currency_unit by using currency and unit column for ppa_tarif and ppa_tariff_dq_1 column\n",
    "def create_currency_unit_dq1(row):\n",
    "    currency = row['ppa_tariff_dq1_currency']\n",
    "    unit = row['ppa_tariff_dq1_unit']\n",
    "    \n",
    "    if pd.notna(currency) and pd.notna(unit):\n",
    "        return f\"{currency}/{unit}\"\n",
    "    elif pd.notna(currency):\n",
    "        return currency\n",
    "    elif pd.notna(unit):\n",
    "        return unit\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "df_unique['ppa_tariff_dq1_currency_unit'] = df_unique.apply(create_currency_unit_dq1, axis=1)\n",
    "\n",
    "def create_currency_unit(row):\n",
    "    currency = row['ppa_tariff_currency']\n",
    "    unit = row['ppa_tariff_unit']\n",
    "    \n",
    "    if pd.notna(currency) and pd.notna(unit):\n",
    "        return f\"{currency}/{unit}\"\n",
    "    elif pd.notna(currency):\n",
    "        return currency\n",
    "    elif pd.notna(unit):\n",
    "        return unit\n",
    "    else:\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "df_unique['ppa_tariff_currency_unit']=df_unique.apply(create_currency_unit,axis=1)\n",
    "\n",
    "## checking the ppa_tariff_dq1_value is numeric \n",
    "df_unique['ppa_tariff_dq1_value'] = pd.to_numeric(df_unique['ppa_tariff_dq1_value'], errors='coerce')\n",
    "\n",
    "### checking the value of tarrif & dq1 value \n",
    "def check_tariff_out_of_range(value, currency):\n",
    "    if pd.notna(value):\n",
    "       \n",
    "        if pd.isna(currency):\n",
    "            currency = 'INR'\n",
    "        \n",
    "       \n",
    "        if currency == 'INR' and (value < 1.9 or value > 12.76):\n",
    "            return 'Yes'\n",
    "       \n",
    "        elif currency == 'USD' and (value < 0.023 or value > 0.15):\n",
    "            return 'Yes'\n",
    "        \n",
    "        else:\n",
    "            return 'No'\n",
    "    else:\n",
    "        return '' \n",
    "\n",
    "df_unique['ppa_tariff_dq1_value_outof_range'] = df_unique.apply(\n",
    "    lambda row: check_tariff_out_of_range(row['ppa_tariff_dq1_value'], row['ppa_tariff_dq1_currency']), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "df_unique['ppa_tariff_value_outof_range'] = df_unique.apply(\n",
    "    lambda row: check_tariff_out_of_range(row['ppa_tariff_value'], row['ppa_tariff_currency']), axis=1\n",
    ")\n",
    "\n",
    "\n",
    "### checking plf value with specific range for creating yes or no column\n",
    "def check_plf_out_of_range(plf_value):\n",
    "    if pd.isna(plf_value):\n",
    "        return ''\n",
    "    \n",
    "    if isinstance(plf_value, str) and '-' in plf_value:\n",
    "        try:\n",
    "            lower, upper = map(float, plf_value.split('-'))\n",
    "            if lower < 18 or upper > 25:\n",
    "                return 'Yes'\n",
    "            else:\n",
    "                return 'No'\n",
    "        except ValueError:\n",
    "            return ''\n",
    "    \n",
    "    try:\n",
    "        plf_value = float(plf_value)\n",
    "        if plf_value < 18 or plf_value > 25:\n",
    "            return 'Yes'\n",
    "        else:\n",
    "            return 'No'\n",
    "    except ValueError:\n",
    "        return ''\n",
    "\n",
    "df_unique['plf_dq1_out_of_range'] = df_unique['plf_dq_1'].apply(check_plf_out_of_range)\n",
    "df_unique['plf_final_out_of_range'] = df_unique['plf_final'].apply(check_plf_out_of_range)\n",
    "\n",
    "### creating ppa_tariff final column by using tariff and dq1 column\n",
    "def create_ppa_tariff_final(row):\n",
    "    ppa_tariff_dq1_value = row['ppa_tariff_dq1_value']\n",
    "    ppa_tariff_value = row['ppa_tariff_value']\n",
    "    ppa_tariff_dq1_currency = row['ppa_tariff_dq1_currency']\n",
    "    ppa_tariff_currency=row['ppa_tariff_currency']\n",
    "    \n",
    "\n",
    "    if check_tariff_out_of_range(ppa_tariff_dq1_value, ppa_tariff_dq1_currency) == 'No':\n",
    "        return ppa_tariff_dq1_value\n",
    "  \n",
    "    elif check_tariff_out_of_range(ppa_tariff_value, ppa_tariff_currency) == 'No':\n",
    "        return ppa_tariff_value\n",
    "    else:\n",
    "        return None  \n",
    "\n",
    "df_unique['ppa_tariff_final'] = df_unique.apply(create_ppa_tariff_final, axis=1)\n",
    "\n",
    "\n",
    "df_unique['ppa_tariff_final_empty'] = df_unique['ppa_tariff_final'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
    "\n",
    "### checking null values for tariff and plf final columns\n",
    "df_unique['ppa_tariff_dq_1_empty'] = df_unique['ppa_tariff_dq_1'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
    "df_unique['plf_dq_1_empty'] = df_unique['plf_dq_1'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
    "df_unique['ppa_tariff_final_empty'] = df_unique['ppa_tariff_final'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
    "df_unique['plf_final_empty'] = df_unique['plf_final'].apply(lambda x: 'Yes' if pd.isna(x) else 'No')\n",
    "\n",
    "\n",
    "output_file_path = 'solar3.xlsx'\n",
    "df_unique.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"ppa_tariff_final column created, and file saved as {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with 'start_year_is_empty' == 'Yes', 'technology_type' == 'Assumed PV', or 'ppa_tariff_final_empty' == 'Yes' have been removed and saved to the output file.\n"
     ]
    }
   ],
   "source": [
    "input_file_path = '/Users/sneha/notebook/nov19-upload_db/solar3.xlsx'  \n",
    "output_file = 'solar_output_file3.xlsx'\n",
    "\n",
    "### finall step to remove all null rows from the dataframe \n",
    "df = pd.read_excel(input_file_path)\n",
    "\n",
    "df = df[(df['start_year_is_empty'] != 'Yes') & \n",
    "        (df['technology_type'] != 'Assumed PV') & \n",
    "        (df['ppa_tariff_final_empty'] != 'Yes') & \n",
    "        (df['plf_final_empty'] != 'Yes') & \n",
    "        (df['ppa_offtaker_is_empty']!= 'Yes')\n",
    "        ]\n",
    "\n",
    "\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Rows with 'start_year_is_empty' == 'Yes', 'technology_type' == 'Assumed PV', or 'ppa_tariff_final_empty' == 'Yes' have been removed and saved to the output file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
